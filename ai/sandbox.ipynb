{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI( api_key=api_key, temperature=0.1) #model_name='gpt-4o',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='3 * 12 is equal to 36.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 15, 'total_tokens': 25}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6c3c3814-a306-4f2c-bb68-8099861eea66-0', usage_metadata={'input_tokens': 15, 'output_tokens': 10, 'total_tokens': 25})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunber of claims:  8\n",
      "Speaker: Kamala Harris\n",
      "Claim: Joe Biden's legacy of accomplishment is unmatched in modern history\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Measurable: No\n",
      "Analysis: This claim is subjective and cannot be objectively measured as it depends on individual interpretation of what constitutes accomplishment and how it compares to other historical figures.\n",
      "\n",
      "Speaker: Kamala Harris\n",
      "Claim: Kamala Harris has earned enough delegates to secure the Democratic nomination\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Measurable: Yes\n",
      "Analysis: This claim is measurable by tracking the number of pledged delegates Kamala Harris has secured in the Democratic primary elections. This data is publicly available and can be quantified to determine if she has reached the threshold for nomination.\n",
      "\n",
      "Speaker: Kamala Harris\n",
      "Claim: Kamala Harris will continue to unite the party to win in November\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Measurable: No\n",
      "Analysis: This claim is subjective and speculative as it pertains to future events. Unity within the party and winning in November are complex outcomes influenced by numerous factors that cannot be definitively measured at this time.\n",
      "\n",
      "Speaker: Kamala Harris\n",
      "Claim: Kamala Harris has a record of taking on perpetrators and holding them accountable\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Measurable: Yes\n",
      "Analysis: This claim is measurable by examining Kamala Harris's past cases as a prosecutor and her actions as a senator. The number of cases prosecuted, convictions secured, and policies implemented can be quantified to assess her record in holding perpetrators accountable.\n",
      "\n",
      "Speaker: Kamala Harris\n",
      "Claim: Kamala Harris's campaign is people-powered and focused on the future\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Measurable: No\n",
      "Analysis: This claim is subjective and lacks specific metrics for measurement. The terms 'people-powered' and 'focused on the future' are open to interpretation and do not have quantifiable criteria for validation.\n",
      "\n",
      "Speaker: Kamala Harris\n",
      "Claim: Donald Trump's agenda will weaken the middle class and cut Social Security and Medicare\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Measurable: No\n",
      "Analysis: This claim is a prediction about future events and policy outcomes, making it unmeasurable at present. The impact of policies on the middle class, Social Security, and Medicare would require real-world data and analysis after implementation to determine their effects.\n",
      "\n",
      "Speaker: Kamala Harris\n",
      "Claim: Kamala Harris's campaign is fighting for the future, freedom, and opportunity\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Measurable: No\n",
      "Analysis: This claim is subjective and lacks specific metrics for measurement. The terms 'fighting for the future, freedom, and opportunity' are broad and open to interpretation, making it difficult to quantify or validate objectively.\n",
      "\n",
      "Speaker: Kamala Harris\n",
      "Claim: Kamala Harris will fight for reproductive freedom and sign laws to restore reproductive freedoms as president\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Measurable: Yes\n",
      "Analysis: This claim is measurable by tracking Kamala Harris's policy proposals, voting record, and public statements related to reproductive rights. The number of bills sponsored, votes cast, and laws signed can be quantified to assess her commitment to reproductive freedom.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "class Claims:\n",
    "    def __init__(self, speaker:str, claim:str, timestamp:str, measurable:bool, analysis:str)->None:\n",
    "        self.speaker = speaker\n",
    "        self.claim = claim\n",
    "        self.measurable = measurable\n",
    "        self.analysis = analysis\n",
    "        self.timestamp = timestamp\n",
    "\n",
    "# Define Pydantic models\n",
    "class ClaimModel(BaseModel):\n",
    "    claim: str\n",
    "    measurable: bool\n",
    "    analysis: str\n",
    "\n",
    "class ClaimList(BaseModel):\n",
    "    claims: List[ClaimModel]\n",
    "\n",
    "# Create the output parser\n",
    "parser = PydanticOutputParser(pydantic_object=ClaimList)\n",
    "\n",
    "# Load the document\n",
    "file_path = \"data/Kamala_Harris_holds_first_campaign_rally_FULL_SPEECH_2024-07-23_190126.txt\"\n",
    "loader = TextLoader(file_path)\n",
    "document = loader.load()\n",
    "\n",
    "# Create an LLM\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Create a prompt to extract speaker from filename\n",
    "extract_speaker_template = ChatPromptTemplate.from_template(\n",
    "    \"Extract the speaker's name from this filename: {filename}. Only return the name, nothing else.\"\n",
    ")\n",
    "\n",
    "# Extract speaker using LLM\n",
    "speaker_chain = extract_speaker_template | llm\n",
    "speaker_result = speaker_chain.invoke({\"filename\": os.path.basename(file_path)})\n",
    "speaker = speaker_result.content.strip()\n",
    "\n",
    "# Get current timestamp\n",
    "timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "# Create the prompt templates for claim extraction and analysis\n",
    "extract_claims_template = ChatPromptTemplate.from_template(\n",
    "    \"Extract claims from the following text:\\n\\n{text}\\n\\n list each claim as a separate bullet point. Claims:\"\n",
    ")\n",
    "\n",
    "analyze_claims_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For each claim, determine if it is measurable or not. If measurable, explain how it could be quantifiably measured or validated using real-world data. If not measurable, explain why it's too vague or subjective to measure. Consider specific metrics, data sources, or methods that could be used for validation.\n",
    "\n",
    "    Format your response as a list of claims with their analysis, following this structure:\n",
    "    {format_instructions}\n",
    "\n",
    "    Claims to analyze:\n",
    "    {claims}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create the LCEL chain for claim extraction and analysis\n",
    "chain = (\n",
    "    {\"text\": lambda x: x['text']}\n",
    "    | extract_claims_template\n",
    "    | llm\n",
    "    | {\"claims\": lambda x: x.content}\n",
    "    | analyze_claims_template.partial(format_instructions=parser.get_format_instructions())\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"text\": document[0].page_content})\n",
    "\n",
    "# Convert the results to Claims objects\n",
    "claims_objects = [\n",
    "    Claims(\n",
    "        speaker=speaker,\n",
    "        claim=claim.claim,\n",
    "        timestamp=timestamp,\n",
    "        measurable=claim.measurable,\n",
    "        analysis=claim.analysis\n",
    "    )\n",
    "    for claim in result.claims\n",
    "]\n",
    "print(\"nunber of claims: \", len(claims_objects))\n",
    "# Print the results\n",
    "for claim in claims_objects:\n",
    "    print(f\"Speaker: {claim.speaker}\")\n",
    "    print(f\"Claim: {claim.claim}\")\n",
    "    print(f\"Timestamp: {claim.timestamp}\")\n",
    "    print(f\"Measurable: {'Yes' if claim.measurable else 'No'}\")\n",
    "    print(f\"Analysis: {claim.analysis}\")\n",
    "    print()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: Kamala Harris\n",
      "Claim: Kamala Harris has earned enough delegates to secure the Democratic nomination\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Analysis: This claim is measurable by tracking the number of pledged delegates Kamala Harris has secured in the Democratic primary elections. This data is publicly available and can be quantified to determine if she has reached the threshold for nomination.\n",
      "\n",
      "Speaker: Kamala Harris\n",
      "Claim: Kamala Harris has a record of taking on perpetrators and holding them accountable\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Analysis: This claim is measurable by examining Kamala Harris's past cases as a prosecutor and her actions as a senator. The number of cases prosecuted, convictions secured, and policies implemented can be quantified to assess her record in holding perpetrators accountable.\n",
      "\n",
      "Speaker: Kamala Harris\n",
      "Claim: Kamala Harris will fight for reproductive freedom and sign laws to restore reproductive freedoms as president\n",
      "Timestamp: 2024-07-28T21:58:10.266963\n",
      "Analysis: This claim is measurable by tracking Kamala Harris's policy proposals, voting record, and public statements related to reproductive rights. The number of bills sponsored, votes cast, and laws signed can be quantified to assess her commitment to reproductive freedom.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for claim in claims_objects:\n",
    "    if claim.measurable:\n",
    "        print(f\"Speaker: {claim.speaker}\")\n",
    "        print(f\"Claim: {claim.claim}\")\n",
    "        print(f\"Timestamp: {claim.timestamp}\")\n",
    "        print(f\"Analysis: {claim.analysis}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (258980941.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 16\u001b[1;36m\u001b[0m\n\u001b[1;33m    for claim in claims:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "SQLALCHEMY_DATABASE_URL = \"sqlite:///./test.db\"\n",
    "\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URL, echo=True)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "\n",
    "db = SessionLocal()\n",
    "try:\n",
    "    yield db\n",
    "finally:\n",
    "    db.close()\n",
    "Base = declarative_base()\n",
    "    for claim in claims:  \n",
    "        # db_claim = Claim(**claim.dict(), video_id=video_id) \n",
    "        print(claim.__str__())\n",
    "        db_claim = Claim(speaker=claim.speaker,\n",
    "            claim=claim.claim,\n",
    "            timestamp=claim.timestamp,\n",
    "            measurable=claim.measurable,  \n",
    "            analysis=claim.analysis, \n",
    "            quote=claim.quote,video_id=video_id)\n",
    "        db.add(db_claim)\n",
    "         \n",
    "    db.commit() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(text('CREATE EXTENSION IF NOT EXISTS vector'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## csv approch\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_community.document_loaders import CSVLoader\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.output_parsers import PydanticOutputParser\n",
    "# from pydantic import BaseModel, Field\n",
    "# from typing import List\n",
    "# import datetime\n",
    "# import os\n",
    "\n",
    "# class Claims:\n",
    "#     def __init__(self, speaker:str, claim:str, timestamp:str, measurable:bool, analysis:str, source_timestamp:str)->None:\n",
    "#         self.speaker = speaker\n",
    "#         self.claim = claim\n",
    "#         self.measurable = measurable\n",
    "#         self.analysis = analysis\n",
    "#         self.timestamp = timestamp\n",
    "#         self.source_timestamp = source_timestamp\n",
    "\n",
    "# # Define Pydantic models\n",
    "# class ClaimModel(BaseModel):\n",
    "#     claim: str\n",
    "#     measurable: bool\n",
    "#     analysis: str\n",
    "#     source_timestamp: str\n",
    "\n",
    "# class ClaimList(BaseModel):\n",
    "#     claims: List[ClaimModel]\n",
    "\n",
    "# # Create the output parser\n",
    "# parser = PydanticOutputParser(pydantic_object=ClaimList)\n",
    "\n",
    "# # Load the document\n",
    "# file_path = \"data/NEW_Trump_Pledges_To_Shut_Down_Department_Of_Education_At_Faith__Freedom_Event__FULL_SPEECH_2024-06-22T203001Z.csv\"\n",
    "# loader = CSVLoader(file_path)\n",
    "# document = loader.load()\n",
    "\n",
    "\n",
    "# # Create a prompt to extract speaker from filename\n",
    "# extract_speaker_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract the speaker's name from this filename: {filename}. Only return the name, nothing else.\"\n",
    "# )\n",
    "\n",
    "# # Extract speaker using LLM\n",
    "# speaker_chain = extract_speaker_template | llm\n",
    "# speaker_result = speaker_chain.invoke({\"filename\": os.path.basename(file_path)})\n",
    "# speaker = speaker_result.content.strip()\n",
    "\n",
    "# # Get current timestamp\n",
    "# timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "# # Create the prompt templates for claim extraction and analysis\n",
    "# extract_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract the most impactful claims made from the following text:\\n\\n{text}\\n\\n List each claim as a separate bullet point. After each claim, include in parentheses () the timestamp from the text that was used to derive the claim. Claims:\"\n",
    "# )\n",
    "\n",
    "# analyze_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"\"\"For each claim, determine if it is measurable or not. If measurable, explain how it could be quantifiably measured or validated using real-world data. If not measurable, explain why it's too vague or subjective to measure. Consider specific metrics, data sources, or methods that could be used for validation.\n",
    "\n",
    "#     Format your response as a list of claims with their analysis, following this structure:\n",
    "#     {format_instructions}\n",
    "\n",
    "#     Claims to analyze:\n",
    "#     {claims}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# # Create the LCEL chain for claim extraction and analysis\n",
    "# chain = (\n",
    "#     {\"text\": lambda x: x['text']}\n",
    "#     | extract_claims_template\n",
    "#     | llm\n",
    "#     | (lambda x: {\"claims\": [{\"claim\": c.split(\"(\")[0], \"source_timestamp\": c.split(\"(\")[1].split(\")\")[0]} for c in x.content.split(\"\\n\") if \"(\" in c and \")\" in c]})\n",
    "#     | analyze_claims_template.partial(format_instructions=parser.get_format_instructions())\n",
    "#     | llm\n",
    "#     | parser\n",
    "# )\n",
    "\n",
    "# # Run the chain\n",
    "# result = chain.invoke({\"text\": document[0].page_content})\n",
    "\n",
    "# # Convert the results to Claims objects\n",
    "# claims_objects = [\n",
    "#     Claims(\n",
    "#         speaker=speaker,\n",
    "#         claim=claim.claim,\n",
    "#         timestamp=timestamp,\n",
    "#         measurable=claim.measurable,\n",
    "#         analysis=claim.analysis,\n",
    "#         source_timestamp=claim.source_timestamp\n",
    "#     )\n",
    "#     for claim in result.claims\n",
    "# ]\n",
    "\n",
    "# print(\"number of claims: \", len(claims_objects))\n",
    "# # Print the results\n",
    "# for claim in claims_objects:\n",
    "#     print(f\"Speaker: {claim.speaker}\")\n",
    "#     print(f\"Claim: {claim.claim}\")\n",
    "#     print(f\"Source Timestamp: {claim.source_timestamp}\")\n",
    "#     print(f\"Timestamp: {claim.timestamp}\")\n",
    "#     print(f\"Measurable: {'Yes' if claim.measurable else 'No'}\")\n",
    "#     print(f\"Analysis: {claim.analysis}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## quote approch\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.output_parsers import PydanticOutputParser\n",
    "# from pydantic import BaseModel, Field\n",
    "# from typing import List\n",
    "# import datetime\n",
    "# import os\n",
    "\n",
    "# class Claims:\n",
    "#     def __init__(self, speaker:str, claim:str, timestamp:str, measurable:bool, analysis:str,quote:str)->None:\n",
    "#         self.speaker = speaker\n",
    "#         self.claim = claim\n",
    "#         self.measurable = measurable\n",
    "#         self.analysis = analysis\n",
    "#         self.timestamp = timestamp\n",
    "#         self.quote = quote\n",
    "\n",
    "# # Define Pydantic models\n",
    "# class ClaimModel(BaseModel):\n",
    "#     claim: str\n",
    "#     measurable: bool\n",
    "#     analysis: str\n",
    "#     quote: str\n",
    "\n",
    "# class ClaimList(BaseModel):\n",
    "#     claims: List[ClaimModel]\n",
    "\n",
    "# # Create the output parser\n",
    "# parser = PydanticOutputParser(pydantic_object=ClaimList)\n",
    "\n",
    "# # Load the document\n",
    "# file_path = \"data/President_Bidens_State_of_the_Union_Address_2024-03-08T034913Z.txt\"\n",
    "# loader = TextLoader(file_path)\n",
    "# document = loader.load()\n",
    "\n",
    "\n",
    "# # Create a prompt to extract speaker from filename\n",
    "# extract_speaker_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract the speaker's name from this filename: {filename}. Only return the name, nothing else.\"\n",
    "# )\n",
    "\n",
    "# # Extract speaker using LLM\n",
    "# speaker_chain = extract_speaker_template | llm\n",
    "# speaker_result = speaker_chain.invoke({\"filename\": os.path.basename(file_path)})\n",
    "# speaker = speaker_result.content.strip()\n",
    "\n",
    "# # Get current timestamp\n",
    "# timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "# # Create the prompt templates for claim extraction and analysis\n",
    "# extract_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract the most impactful claims made from the following text:\\n\\n{text}\\n\\n List each claim as a separate bullet point. After each claim, include in parentheses () the partial quote from the text that was used to derive the claim. Claims:\"\n",
    "# )\n",
    "\n",
    "# analyze_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"\"\"For each claim, determine if it is measurable or not. If measurable, explain how it could be quantifiably measured or validated using real-world data. If not measurable, explain why it's too vague or subjective to measure. Consider specific metrics, data sources, or methods that could be used for validation.\n",
    "\n",
    "#     Format your response as a list of claims with their analysis, following this structure:\n",
    "#     {format_instructions}\n",
    "\n",
    "#     Claims to analyze:\n",
    "#     {claims}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# # Create the LCEL chain for claim extraction and analysis\n",
    "# chain = (\n",
    "#     {\"text\": lambda x: x['text']}\n",
    "#     | extract_claims_template\n",
    "#     | llm\n",
    "#     | (lambda x: {\"claims\": [{\"claim\": c.split(\"(\")[0], \"quote\": c.split(\"(\")[1].split(\")\")[0]} for c in x.content.split(\"\\n\") if \"(\" in c and \")\" in c]})\n",
    "#     | analyze_claims_template.partial(format_instructions=parser.get_format_instructions())\n",
    "#     | llm\n",
    "#     | parser\n",
    "# )\n",
    "\n",
    "# # Run the chain\n",
    "# result = chain.invoke({\"text\": document[0].page_content})\n",
    "\n",
    "# # Convert the results to Claims objects\n",
    "# claims_objects = [\n",
    "#     Claims(\n",
    "#         speaker=speaker,\n",
    "#         claim=claim.claim,\n",
    "#         timestamp=timestamp,\n",
    "#         measurable=claim.measurable,\n",
    "#         analysis=claim.analysis,\n",
    "#         quote=claim.quote\n",
    "#     )\n",
    "#     for claim in result.claims\n",
    "# ]\n",
    "\n",
    "# print(\"nunber of claims: \", len(claims_objects))\n",
    "# # Print the results\n",
    "# for claim in claims_objects:\n",
    "#     print(f\"Speaker: {claim.speaker}\")\n",
    "#     print(f\"Claim: {claim.claim}\")\n",
    "#     print(f\"Quote: {claim.quote}\")\n",
    "#     print(f\"Timestamp: {claim.timestamp}\")\n",
    "#     print(f\"Measurable: {'Yes' if claim.measurable else 'No'}\")\n",
    "#     print(f\"Analysis: {claim.analysis}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chracther index approch\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.output_parsers import PydanticOutputParser\n",
    "# from pydantic import BaseModel, Field\n",
    "# from typing import List\n",
    "# import datetime\n",
    "# import os\n",
    "\n",
    "# # Import the Claims class\n",
    "# # from models.claims import Claims\n",
    "\n",
    "# class Claims:\n",
    "#     def __init__(self, speaker:str, claim:str, timestamp:str, measurable:bool, analysis:str, char_indices:tuple)->None:\n",
    "#         self.speaker = speaker\n",
    "#         self.claim = claim\n",
    "#         self.measurable = measurable\n",
    "#         self.analysis = analysis\n",
    "#         self.timestamp = timestamp\n",
    "#         self.char_indices = char_indices\n",
    "\n",
    "# # Define a Pydantic model that matches the Claims class\n",
    "# class ClaimModel(BaseModel):\n",
    "#     speaker: str\n",
    "#     claim: str\n",
    "#     timestamp: str\n",
    "#     measurable: bool\n",
    "#     analysis: str\n",
    "#     char_indices: str\n",
    "\n",
    "\n",
    "# class ClaimList(BaseModel):\n",
    "#     claims: List[ClaimModel]\n",
    "\n",
    "# # Create the output parser\n",
    "# parser = PydanticOutputParser(pydantic_object=ClaimList)\n",
    "\n",
    "# # Load the document\n",
    "# file_path = \"data/President_Bidens_State_of_the_Union_Address_2024-03-08T034913Z.txt\"\n",
    "# loader = TextLoader(file_path)\n",
    "# document = loader.load()\n",
    "\n",
    "# # Get current timestamp\n",
    "# timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "# # Create a prompt to extract speaker from filename\n",
    "# extract_speaker_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract the speaker's name from this filename: {filename}. Only return the name, nothing else.\"\n",
    "# )\n",
    "\n",
    "# # Extract speaker using LLM\n",
    "# speaker_chain = extract_speaker_template | llm\n",
    "# speaker_result = speaker_chain.invoke({\"filename\": os.path.basename(file_path)})\n",
    "# speaker = speaker_result.content.strip()\n",
    "\n",
    "# # Create the prompt templates\n",
    "# extract_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract claims from the following text:\\n\\n{text}\\n\\n For each claim, list it as a separate bullet point and include the starting and ending character indices in parentheses. Claims:\"\n",
    "# )\n",
    "\n",
    "\n",
    "# analyze_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"\"\"For each claim, determine if it is measurable or not. If measurable, explain how it could be quantifiably measured or validated using real-world data. If not measurable, explain why it's too vague or subjective to measure. Consider specific metrics, data sources, or methods that could be used for validation.\n",
    "\n",
    "#     Format your response as a list of claims with their analysis, following this structure:\n",
    "#     {format_instructions}\n",
    "\n",
    "#     Claims to analyze:\n",
    "#     {claims}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "\n",
    "# # Create the LCEL chain\n",
    "# chain = (\n",
    "#     {\"text\": lambda x: x['text']}\n",
    "#     | extract_claims_template\n",
    "#     | llm\n",
    "#     | (lambda x: {\"claims\": [{\"claim\": c.split(\"(\")[0], \"char_indices\": c.split(\"(\")[1].split(\")\")[0]} for c in x.content.split(\"\\n\") if \"(\" in c and \")\" in c]})\n",
    "#     | analyze_claims_template.partial(format_instructions=parser.get_format_instructions())\n",
    "#     | llm\n",
    "#     | parser\n",
    "# )\n",
    "\n",
    "\n",
    "# # Run the chain\n",
    "# result = chain.invoke({\"text\": document[0].page_content})\n",
    "\n",
    "# # Convert the results to Claims objects\n",
    "# claims_objects = [\n",
    "#     Claims(\n",
    "#         speaker=speaker,\n",
    "#         claim=claim.claim,\n",
    "#         timestamp=timestamp,\n",
    "#         measurable=claim.measurable,\n",
    "#         analysis=claim.analysis,\n",
    "#         char_indices=claim.char_indices\n",
    "#     )\n",
    "#     for claim in result.claims\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Print the results\n",
    "# for claim in claims_objects:\n",
    "#     print(f\"Speaker: {claim.speaker}\")\n",
    "#     print(f\"Claim: {claim.claim}\")\n",
    "#     print(f\"Timestamp: {claim.timestamp}\")\n",
    "#     print(f\"Measurable: {'Yes' if claim.measurable else 'No'}\")\n",
    "#     print(f\"Analysis: {claim.analysis}\")\n",
    "#     print(f\"char_indices:{claim.char_indices}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
