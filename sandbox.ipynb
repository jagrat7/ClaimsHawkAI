{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model_name='gpt-4o', api_key=api_key, temperature=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='3 multiplied by 12 equals 36.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 15, 'total_tokens': 24}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_400f27fa1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-b1889219-024b-433e-917f-05c43fee52da-0', usage_metadata={'input_tokens': 15, 'output_tokens': 9, 'total_tokens': 24})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunber of claims:  10\n",
      "Speaker: President Biden\n",
      "Claim: The President has signed over 400 bipartisan bills.\n",
      "Timestamp: 2024-07-22T01:46:53.841435\n",
      "Measurable: Yes\n",
      "Analysis: This claim is measurable by examining the number of bills signed by the President that received bipartisan support. This data can be obtained from official government records and reports.\n",
      "\n",
      "Speaker: President Biden\n",
      "Claim: The President has made the largest investment in public safety ever.\n",
      "Timestamp: 2024-07-22T01:46:53.841435\n",
      "Measurable: No\n",
      "Analysis: This claim is not measurable as 'largest investment' is subjective and lacks specific metrics for comparison. Without clear data on the amount invested in public safety by previous administrations, it is challenging to quantify this claim.\n",
      "\n",
      "Speaker: President Biden\n",
      "Claim: The murder rate saw the sharpest decrease in history under the President's administration.\n",
      "Timestamp: 2024-07-22T01:46:53.841435\n",
      "Measurable: Yes\n",
      "Analysis: This claim is measurable by comparing historical murder rate data before and during the President's administration. Data from official crime reports and statistics can be used to validate this claim.\n",
      "\n",
      "Speaker: President Biden\n",
      "Claim: The President has revitalized partnerships and alliances in the Pacific.\n",
      "Timestamp: 2024-07-22T01:46:53.841435\n",
      "Measurable: No\n",
      "Analysis: This claim is not measurable as 'revitalized partnerships and alliances' is vague and lacks specific indicators or metrics for assessment. Without concrete data on the state of partnerships and alliances in the Pacific before and after the President's actions, it is challenging to quantify this claim.\n",
      "\n",
      "Speaker: President Biden\n",
      "Claim: The President has cut the trade deficit with China to the lowest point in over a decade.\n",
      "Timestamp: 2024-07-22T01:46:53.841435\n",
      "Measurable: Yes\n",
      "Analysis: This claim is measurable by comparing the trade deficit with China over the past decade and assessing if it is currently at its lowest point. Trade data and reports from government agencies can be used to validate this claim.\n",
      "\n",
      "Speaker: President Biden\n",
      "Claim: The President has taken significant action on climate change.\n",
      "Timestamp: 2024-07-22T01:46:53.841435\n",
      "Measurable: No\n",
      "Analysis: This claim is not measurable as 'significant action' is subjective and lacks specific actions or policies to quantify. Without clear metrics on what constitutes significant action on climate change, it is challenging to assess the validity of this claim.\n",
      "\n",
      "Speaker: President Biden\n",
      "Claim: The President has signed the most significant gun safety law in nearly 30 years.\n",
      "Timestamp: 2024-07-22T01:46:53.841435\n",
      "Measurable: No\n",
      "Analysis: This claim is not measurable as 'most significant gun safety law' is subjective and lacks specific criteria for comparison. Without clear data on the impact and scope of gun safety laws over the past 30 years, it is challenging to quantify this claim.\n",
      "\n",
      "Speaker: President Biden\n",
      "Claim: The President has established the first-ever Office of Gun Violence Prevention in the White House.\n",
      "Timestamp: 2024-07-22T01:46:53.841435\n",
      "Measurable: Yes\n",
      "Analysis: This claim is measurable by confirming the establishment of the Office of Gun Violence Prevention in the White House through official announcements or documentation. The creation of this office can be validated using government records.\n",
      "\n",
      "Speaker: President Biden\n",
      "Claim: The President has signed the PACT Act to help veterans exposed to toxins.\n",
      "Timestamp: 2024-07-22T01:46:53.841435\n",
      "Measurable: Yes\n",
      "Analysis: This claim is measurable by confirming the signing of the PACT Act and assessing its provisions to support veterans exposed to toxins. The content of the act and its impact on veterans can be validated through legislative records and reports.\n",
      "\n",
      "Speaker: President Biden\n",
      "Claim: The President has built a coalition of more than a dozen countries to defend international shipping in the Red Sea.\n",
      "Timestamp: 2024-07-22T01:46:53.841435\n",
      "Measurable: Yes\n",
      "Analysis: This claim is measurable by identifying the countries involved in the coalition and confirming their participation in defending international shipping in the Red Sea. Official statements and diplomatic reports can be used to validate the formation of this coalition.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "class Claims:\n",
    "    def __init__(self, speaker:str, claim:str, timestamp:str, measurable:bool, analysis:str)->None:\n",
    "        self.speaker = speaker\n",
    "        self.claim = claim\n",
    "        self.measurable = measurable\n",
    "        self.analysis = analysis\n",
    "        self.timestamp = timestamp\n",
    "\n",
    "# Define Pydantic models\n",
    "class ClaimModel(BaseModel):\n",
    "    claim: str\n",
    "    measurable: bool\n",
    "    analysis: str\n",
    "\n",
    "class ClaimList(BaseModel):\n",
    "    claims: List[ClaimModel]\n",
    "\n",
    "# Create the output parser\n",
    "parser = PydanticOutputParser(pydantic_object=ClaimList)\n",
    "\n",
    "# Load the document\n",
    "file_path = \"data/President_Bidens_State_of_the_Union_Address_2024-03-08T034913Z.txt\"\n",
    "loader = TextLoader(file_path)\n",
    "document = loader.load()\n",
    "\n",
    "# Create an LLM\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Create a prompt to extract speaker from filename\n",
    "extract_speaker_template = ChatPromptTemplate.from_template(\n",
    "    \"Extract the speaker's name from this filename: {filename}. Only return the name, nothing else.\"\n",
    ")\n",
    "\n",
    "# Extract speaker using LLM\n",
    "speaker_chain = extract_speaker_template | llm\n",
    "speaker_result = speaker_chain.invoke({\"filename\": os.path.basename(file_path)})\n",
    "speaker = speaker_result.content.strip()\n",
    "\n",
    "# Get current timestamp\n",
    "timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "# Create the prompt templates for claim extraction and analysis\n",
    "extract_claims_template = ChatPromptTemplate.from_template(\n",
    "    \"Extract claims from the following text:\\n\\n{text}\\n\\n list each claim as a separate bullet point. Claims:\"\n",
    ")\n",
    "\n",
    "analyze_claims_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For each claim, determine if it is measurable or not. If measurable, explain how it could be quantifiably measured or validated using real-world data. If not measurable, explain why it's too vague or subjective to measure. Consider specific metrics, data sources, or methods that could be used for validation.\n",
    "\n",
    "    Format your response as a list of claims with their analysis, following this structure:\n",
    "    {format_instructions}\n",
    "\n",
    "    Claims to analyze:\n",
    "    {claims}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create the LCEL chain for claim extraction and analysis\n",
    "chain = (\n",
    "    {\"text\": lambda x: x['text']}\n",
    "    | extract_claims_template\n",
    "    | llm\n",
    "    | {\"claims\": lambda x: x.content}\n",
    "    | analyze_claims_template.partial(format_instructions=parser.get_format_instructions())\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"text\": document[0].page_content})\n",
    "\n",
    "# Convert the results to Claims objects\n",
    "claims_objects = [\n",
    "    Claims(\n",
    "        speaker=speaker,\n",
    "        claim=claim.claim,\n",
    "        timestamp=timestamp,\n",
    "        measurable=claim.measurable,\n",
    "        analysis=claim.analysis\n",
    "    )\n",
    "    for claim in result.claims\n",
    "]\n",
    "print(\"nunber of claims: \", len(claims_objects))\n",
    "# Print the results\n",
    "for claim in claims_objects:\n",
    "    print(f\"Speaker: {claim.speaker}\")\n",
    "    print(f\"Claim: {claim.claim}\")\n",
    "    print(f\"Timestamp: {claim.timestamp}\")\n",
    "    print(f\"Measurable: {'Yes' if claim.measurable else 'No'}\")\n",
    "    print(f\"Analysis: {claim.analysis}\")\n",
    "    print()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "SQLALCHEMY_DATABASE_URL = \"sqlite:///./test.db\"\n",
    "\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URL, echo=True)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "\n",
    "db = SessionLocal()\n",
    "try:\n",
    "    yield db\n",
    "finally:\n",
    "    db.close()\n",
    "Base = declarative_base()\n",
    "    for claim in claims:  \n",
    "        # db_claim = Claim(**claim.dict(), video_id=video_id) \n",
    "        print(claim.__str__())\n",
    "        db_claim = Claim(speaker=claim.speaker,\n",
    "            claim=claim.claim,\n",
    "            timestamp=claim.timestamp,\n",
    "            measurable=claim.measurable,  \n",
    "            analysis=claim.analysis, \n",
    "            quote=claim.quote,video_id=video_id)\n",
    "        db.add(db_claim)\n",
    "         \n",
    "    db.commit() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(text('CREATE EXTENSION IF NOT EXISTS vector'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## csv approch\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_community.document_loaders import CSVLoader\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.output_parsers import PydanticOutputParser\n",
    "# from pydantic import BaseModel, Field\n",
    "# from typing import List\n",
    "# import datetime\n",
    "# import os\n",
    "\n",
    "# class Claims:\n",
    "#     def __init__(self, speaker:str, claim:str, timestamp:str, measurable:bool, analysis:str, source_timestamp:str)->None:\n",
    "#         self.speaker = speaker\n",
    "#         self.claim = claim\n",
    "#         self.measurable = measurable\n",
    "#         self.analysis = analysis\n",
    "#         self.timestamp = timestamp\n",
    "#         self.source_timestamp = source_timestamp\n",
    "\n",
    "# # Define Pydantic models\n",
    "# class ClaimModel(BaseModel):\n",
    "#     claim: str\n",
    "#     measurable: bool\n",
    "#     analysis: str\n",
    "#     source_timestamp: str\n",
    "\n",
    "# class ClaimList(BaseModel):\n",
    "#     claims: List[ClaimModel]\n",
    "\n",
    "# # Create the output parser\n",
    "# parser = PydanticOutputParser(pydantic_object=ClaimList)\n",
    "\n",
    "# # Load the document\n",
    "# file_path = \"data/NEW_Trump_Pledges_To_Shut_Down_Department_Of_Education_At_Faith__Freedom_Event__FULL_SPEECH_2024-06-22T203001Z.csv\"\n",
    "# loader = CSVLoader(file_path)\n",
    "# document = loader.load()\n",
    "\n",
    "\n",
    "# # Create a prompt to extract speaker from filename\n",
    "# extract_speaker_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract the speaker's name from this filename: {filename}. Only return the name, nothing else.\"\n",
    "# )\n",
    "\n",
    "# # Extract speaker using LLM\n",
    "# speaker_chain = extract_speaker_template | llm\n",
    "# speaker_result = speaker_chain.invoke({\"filename\": os.path.basename(file_path)})\n",
    "# speaker = speaker_result.content.strip()\n",
    "\n",
    "# # Get current timestamp\n",
    "# timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "# # Create the prompt templates for claim extraction and analysis\n",
    "# extract_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract the most impactful claims made from the following text:\\n\\n{text}\\n\\n List each claim as a separate bullet point. After each claim, include in parentheses () the timestamp from the text that was used to derive the claim. Claims:\"\n",
    "# )\n",
    "\n",
    "# analyze_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"\"\"For each claim, determine if it is measurable or not. If measurable, explain how it could be quantifiably measured or validated using real-world data. If not measurable, explain why it's too vague or subjective to measure. Consider specific metrics, data sources, or methods that could be used for validation.\n",
    "\n",
    "#     Format your response as a list of claims with their analysis, following this structure:\n",
    "#     {format_instructions}\n",
    "\n",
    "#     Claims to analyze:\n",
    "#     {claims}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# # Create the LCEL chain for claim extraction and analysis\n",
    "# chain = (\n",
    "#     {\"text\": lambda x: x['text']}\n",
    "#     | extract_claims_template\n",
    "#     | llm\n",
    "#     | (lambda x: {\"claims\": [{\"claim\": c.split(\"(\")[0], \"source_timestamp\": c.split(\"(\")[1].split(\")\")[0]} for c in x.content.split(\"\\n\") if \"(\" in c and \")\" in c]})\n",
    "#     | analyze_claims_template.partial(format_instructions=parser.get_format_instructions())\n",
    "#     | llm\n",
    "#     | parser\n",
    "# )\n",
    "\n",
    "# # Run the chain\n",
    "# result = chain.invoke({\"text\": document[0].page_content})\n",
    "\n",
    "# # Convert the results to Claims objects\n",
    "# claims_objects = [\n",
    "#     Claims(\n",
    "#         speaker=speaker,\n",
    "#         claim=claim.claim,\n",
    "#         timestamp=timestamp,\n",
    "#         measurable=claim.measurable,\n",
    "#         analysis=claim.analysis,\n",
    "#         source_timestamp=claim.source_timestamp\n",
    "#     )\n",
    "#     for claim in result.claims\n",
    "# ]\n",
    "\n",
    "# print(\"number of claims: \", len(claims_objects))\n",
    "# # Print the results\n",
    "# for claim in claims_objects:\n",
    "#     print(f\"Speaker: {claim.speaker}\")\n",
    "#     print(f\"Claim: {claim.claim}\")\n",
    "#     print(f\"Source Timestamp: {claim.source_timestamp}\")\n",
    "#     print(f\"Timestamp: {claim.timestamp}\")\n",
    "#     print(f\"Measurable: {'Yes' if claim.measurable else 'No'}\")\n",
    "#     print(f\"Analysis: {claim.analysis}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## quote approch\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.output_parsers import PydanticOutputParser\n",
    "# from pydantic import BaseModel, Field\n",
    "# from typing import List\n",
    "# import datetime\n",
    "# import os\n",
    "\n",
    "# class Claims:\n",
    "#     def __init__(self, speaker:str, claim:str, timestamp:str, measurable:bool, analysis:str,quote:str)->None:\n",
    "#         self.speaker = speaker\n",
    "#         self.claim = claim\n",
    "#         self.measurable = measurable\n",
    "#         self.analysis = analysis\n",
    "#         self.timestamp = timestamp\n",
    "#         self.quote = quote\n",
    "\n",
    "# # Define Pydantic models\n",
    "# class ClaimModel(BaseModel):\n",
    "#     claim: str\n",
    "#     measurable: bool\n",
    "#     analysis: str\n",
    "#     quote: str\n",
    "\n",
    "# class ClaimList(BaseModel):\n",
    "#     claims: List[ClaimModel]\n",
    "\n",
    "# # Create the output parser\n",
    "# parser = PydanticOutputParser(pydantic_object=ClaimList)\n",
    "\n",
    "# # Load the document\n",
    "# file_path = \"data/President_Bidens_State_of_the_Union_Address_2024-03-08T034913Z.txt\"\n",
    "# loader = TextLoader(file_path)\n",
    "# document = loader.load()\n",
    "\n",
    "\n",
    "# # Create a prompt to extract speaker from filename\n",
    "# extract_speaker_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract the speaker's name from this filename: {filename}. Only return the name, nothing else.\"\n",
    "# )\n",
    "\n",
    "# # Extract speaker using LLM\n",
    "# speaker_chain = extract_speaker_template | llm\n",
    "# speaker_result = speaker_chain.invoke({\"filename\": os.path.basename(file_path)})\n",
    "# speaker = speaker_result.content.strip()\n",
    "\n",
    "# # Get current timestamp\n",
    "# timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "# # Create the prompt templates for claim extraction and analysis\n",
    "# extract_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract the most impactful claims made from the following text:\\n\\n{text}\\n\\n List each claim as a separate bullet point. After each claim, include in parentheses () the partial quote from the text that was used to derive the claim. Claims:\"\n",
    "# )\n",
    "\n",
    "# analyze_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"\"\"For each claim, determine if it is measurable or not. If measurable, explain how it could be quantifiably measured or validated using real-world data. If not measurable, explain why it's too vague or subjective to measure. Consider specific metrics, data sources, or methods that could be used for validation.\n",
    "\n",
    "#     Format your response as a list of claims with their analysis, following this structure:\n",
    "#     {format_instructions}\n",
    "\n",
    "#     Claims to analyze:\n",
    "#     {claims}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# # Create the LCEL chain for claim extraction and analysis\n",
    "# chain = (\n",
    "#     {\"text\": lambda x: x['text']}\n",
    "#     | extract_claims_template\n",
    "#     | llm\n",
    "#     | (lambda x: {\"claims\": [{\"claim\": c.split(\"(\")[0], \"quote\": c.split(\"(\")[1].split(\")\")[0]} for c in x.content.split(\"\\n\") if \"(\" in c and \")\" in c]})\n",
    "#     | analyze_claims_template.partial(format_instructions=parser.get_format_instructions())\n",
    "#     | llm\n",
    "#     | parser\n",
    "# )\n",
    "\n",
    "# # Run the chain\n",
    "# result = chain.invoke({\"text\": document[0].page_content})\n",
    "\n",
    "# # Convert the results to Claims objects\n",
    "# claims_objects = [\n",
    "#     Claims(\n",
    "#         speaker=speaker,\n",
    "#         claim=claim.claim,\n",
    "#         timestamp=timestamp,\n",
    "#         measurable=claim.measurable,\n",
    "#         analysis=claim.analysis,\n",
    "#         quote=claim.quote\n",
    "#     )\n",
    "#     for claim in result.claims\n",
    "# ]\n",
    "\n",
    "# print(\"nunber of claims: \", len(claims_objects))\n",
    "# # Print the results\n",
    "# for claim in claims_objects:\n",
    "#     print(f\"Speaker: {claim.speaker}\")\n",
    "#     print(f\"Claim: {claim.claim}\")\n",
    "#     print(f\"Quote: {claim.quote}\")\n",
    "#     print(f\"Timestamp: {claim.timestamp}\")\n",
    "#     print(f\"Measurable: {'Yes' if claim.measurable else 'No'}\")\n",
    "#     print(f\"Analysis: {claim.analysis}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## chracther index approch\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_community.document_loaders import TextLoader\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.output_parsers import PydanticOutputParser\n",
    "# from pydantic import BaseModel, Field\n",
    "# from typing import List\n",
    "# import datetime\n",
    "# import os\n",
    "\n",
    "# # Import the Claims class\n",
    "# # from models.claims import Claims\n",
    "\n",
    "# class Claims:\n",
    "#     def __init__(self, speaker:str, claim:str, timestamp:str, measurable:bool, analysis:str, char_indices:tuple)->None:\n",
    "#         self.speaker = speaker\n",
    "#         self.claim = claim\n",
    "#         self.measurable = measurable\n",
    "#         self.analysis = analysis\n",
    "#         self.timestamp = timestamp\n",
    "#         self.char_indices = char_indices\n",
    "\n",
    "# # Define a Pydantic model that matches the Claims class\n",
    "# class ClaimModel(BaseModel):\n",
    "#     speaker: str\n",
    "#     claim: str\n",
    "#     timestamp: str\n",
    "#     measurable: bool\n",
    "#     analysis: str\n",
    "#     char_indices: str\n",
    "\n",
    "\n",
    "# class ClaimList(BaseModel):\n",
    "#     claims: List[ClaimModel]\n",
    "\n",
    "# # Create the output parser\n",
    "# parser = PydanticOutputParser(pydantic_object=ClaimList)\n",
    "\n",
    "# # Load the document\n",
    "# file_path = \"data/President_Bidens_State_of_the_Union_Address_2024-03-08T034913Z.txt\"\n",
    "# loader = TextLoader(file_path)\n",
    "# document = loader.load()\n",
    "\n",
    "# # Get current timestamp\n",
    "# timestamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "# # Create a prompt to extract speaker from filename\n",
    "# extract_speaker_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract the speaker's name from this filename: {filename}. Only return the name, nothing else.\"\n",
    "# )\n",
    "\n",
    "# # Extract speaker using LLM\n",
    "# speaker_chain = extract_speaker_template | llm\n",
    "# speaker_result = speaker_chain.invoke({\"filename\": os.path.basename(file_path)})\n",
    "# speaker = speaker_result.content.strip()\n",
    "\n",
    "# # Create the prompt templates\n",
    "# extract_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"Extract claims from the following text:\\n\\n{text}\\n\\n For each claim, list it as a separate bullet point and include the starting and ending character indices in parentheses. Claims:\"\n",
    "# )\n",
    "\n",
    "\n",
    "# analyze_claims_template = ChatPromptTemplate.from_template(\n",
    "#     \"\"\"For each claim, determine if it is measurable or not. If measurable, explain how it could be quantifiably measured or validated using real-world data. If not measurable, explain why it's too vague or subjective to measure. Consider specific metrics, data sources, or methods that could be used for validation.\n",
    "\n",
    "#     Format your response as a list of claims with their analysis, following this structure:\n",
    "#     {format_instructions}\n",
    "\n",
    "#     Claims to analyze:\n",
    "#     {claims}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "\n",
    "# # Create the LCEL chain\n",
    "# chain = (\n",
    "#     {\"text\": lambda x: x['text']}\n",
    "#     | extract_claims_template\n",
    "#     | llm\n",
    "#     | (lambda x: {\"claims\": [{\"claim\": c.split(\"(\")[0], \"char_indices\": c.split(\"(\")[1].split(\")\")[0]} for c in x.content.split(\"\\n\") if \"(\" in c and \")\" in c]})\n",
    "#     | analyze_claims_template.partial(format_instructions=parser.get_format_instructions())\n",
    "#     | llm\n",
    "#     | parser\n",
    "# )\n",
    "\n",
    "\n",
    "# # Run the chain\n",
    "# result = chain.invoke({\"text\": document[0].page_content})\n",
    "\n",
    "# # Convert the results to Claims objects\n",
    "# claims_objects = [\n",
    "#     Claims(\n",
    "#         speaker=speaker,\n",
    "#         claim=claim.claim,\n",
    "#         timestamp=timestamp,\n",
    "#         measurable=claim.measurable,\n",
    "#         analysis=claim.analysis,\n",
    "#         char_indices=claim.char_indices\n",
    "#     )\n",
    "#     for claim in result.claims\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Print the results\n",
    "# for claim in claims_objects:\n",
    "#     print(f\"Speaker: {claim.speaker}\")\n",
    "#     print(f\"Claim: {claim.claim}\")\n",
    "#     print(f\"Timestamp: {claim.timestamp}\")\n",
    "#     print(f\"Measurable: {'Yes' if claim.measurable else 'No'}\")\n",
    "#     print(f\"Analysis: {claim.analysis}\")\n",
    "#     print(f\"char_indices:{claim.char_indices}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
